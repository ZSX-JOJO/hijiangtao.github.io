---
title: 提示工程最佳实践：如何与 AI 更好地对话
layout: post
thread: 299
date: 2025-11-26
author: Joe Jiang
categories: Document
tags: [2025, 提示工程, 最佳实践, 对话, AI, Prompt, PE]
excerpt: 提示工程（Prompt Engineering）是指通过设计和优化提示（Prompt），与 AI 模型（如 GPT-3、GPT-4 等）进行交互，以实现期望的输出结果。在这篇文章中，我们将探讨提示工程的最佳实践，帮助你更好地与 AI 模型对话。
toc: true
header:
  image: ../assets/in-post/2025-11-26-Prompt-Engineering-Best-Practices-Teaser.png
  caption: "©️hijiangtao"
---

Claude 最近新发了一篇关于提示工程最佳实践的文章，其中提到了诸多如何更好的写好提示词以利用 AI 帮助大家精准解决问题的思路，太长不看可以直接拿走这份思维导图。以下正文会详细给大家分享一下我认为文章还不错的很多精华部分。

![](/assets/in-post/2025-11-26-Prompt-Engineering-Best-Practices-MindMap.png)

什么是提示工程？其本质是修改传递给大语言模型（LLM）的查询，核心是在实际请求前添加 “正确的信息”。提示工程的核心价值在于：

- 提示工程是构建指令以从AI模型获得更优输出的技巧，包括表述查询、指定风格、提供上下文和引导模型行为等方面。
- 模糊指令与精心设计的提示差异显著：前者可能需要多次沟通澄清意图，后者可一次性达成目标。
- 提示工程是上下文工程的核心组成部分，与对话历史、附加文件和系统指令协同作用，共同优化AI输出结果。

一个合适的学习路径应该是先掌握基础习惯，再逐步应用复杂项目的高级方法。

## 一、核心基础技术

### 1. 指令明确清晰

核心原则：直接告知模型期望的结果，不假设模型能推断需求，使用简洁无歧义的语言。

**最佳实践**
- 以直接的动作动词开头（如“撰写”、“分析”、“生成”、“创建”）。
- 跳过开场白，直接切入请求核心。
- 明确输出应包含的内容，而非仅说明处理对象。
- 具体说明对质量和深度的期望。

**示例对比**
```
模糊表述：“创建一个分析仪表板”
明确表述：“创建一个分析仪表板，包含尽可能多的相关功能和交互，超越基础要求，实现功能完备的方案”
```

### 2. 提供上下文与动机

核心价值：解释需求背后的原因，帮助AI理解核心目标，生成更具针对性的响应（对能推理潜在目标的新型模型尤为有效）。

**适用场景**
- 说明输出的用途或受众。
- 解释特定约束存在的原因。
- 描述输出的使用方式。
- 指明要解决的具体问题。

**示例对比**
```
效果较差：“绝不要使用项目符号”
效果更佳：“我偏好自然段落形式的响应而非项目符号，因为流畅的散文更易阅读且更具对话感，项目符号对我的轻松学习风格而言过于正式和列表化”
```

### 3. 指令具体化

核心要求：通过明确的指导方针和要求构建指令，具体程度越高，结果越优。

**需包含的关键要素**
- 明确约束（字数、格式、时间线）。
- 相关上下文（受众、目标）。
- 期望的输出结构（表格、列表、段落）。
- 任何要求或限制（饮食需求、预算限制、技术约束）。

**示例对比**
```
模糊表述：“创建地中海饮食的膳食计划”
具体表述：“设计一份用于糖尿病前期管理的地中海饮食膳食计划，每日1800卡路里，重点关注低血糖指数食物，包含早餐、午餐、晚餐和一份加餐，并提供完整的营养成分分析”
```

### 4. 使用示例（单样本/少样本提示）

核心作用：通过示例直观展示期望的格式、语气或模式，比纯描述更易澄清复杂需求。

**注意事项**：现代模型（如Claude 4.x）会密切关注示例细节，需确保示例与期望行为一致，避免传递不良模式。

**适用场景**
- 期望格式难以用文字描述。
- 需要特定语气或风格。
- 任务涉及微妙模式或惯例。
- 简单指令无法产生一致结果。

**实用技巧**
- 先尝试1个示例（单样本），仅在输出不符合需求时添加更多示例（少样本）。

**示例对比**
```
无示例：“总结这篇文章”
带示例：“以下是我想要的总结风格示例：文章：[AI监管相关文章链接] 总结：欧盟通过全面的《人工智能法案》，针对高风险系统，核心条款包括透明度要求和人类监督规定，2026年生效。 现在按相同风格总结这篇文章：[新文章链接]”
```

### 5. 允许AI表达不确定性

核心目的：减少模型的幻觉（虚构信息），提高响应的可靠性。

**示例**
```
分析这份财务数据并识别趋势，若数据不足以得出结论，请直接说明，不要猜测
```

## 二、高级复杂场景技术
### 1. 预填充AI响应

核心作用：提前启动AI的响应内容，引导输出的格式、语气或结构。

**适用场景**
- 需要输出JSON、XML等结构化格式。
- 希望跳过对话开场白，直接获取核心内容。
- 需维持特定语气或角色。
- 要控制AI的响应开头方式。

### 2. 思维链提示（CoT）

定义：要求AI在给出答案前进行分步推理，适用于复杂分析任务。

**适用场景**
- 无“扩展思考”功能可用。
- 需要可审查的透明推理过程。
- 任务涉及多步分析。
- 需确保AI考虑特定因素。

**三种常见实现方式**
- 基础思维链：在指令中添加“分步思考”。示例：“为Care for Kids项目撰写个性化捐赠请求邮件，先分步思考再动笔”。
- 引导式思维链：指定具体推理阶段。示例：“撰写邮件前先思考：1. 根据捐赠者历史，哪些信息可能吸引他们；2. Care for Kids项目的哪些方面能引起共鸣；3. 基于分析撰写个性化邮件”。
- 结构化思维链：用标签分隔推理过程与最终答案。示例：“用`<thinking>`标签记录思考过程（分析吸引捐赠者的信息、项目相关亮点），用`<email>`标签呈现最终邮件”。

注意事项：“扩展思考”与手动CoT可互补使用，复杂任务中结合使用效果更佳。

### 3. 控制输出格式

核心原则：通过正向引导、风格匹配和明确要求实现格式控制。

**三种有效方法**
- 正向指令优先：不说“不要做什么”，而说“要做什么”。示例：不说“不要使用Markdown”，而说“响应应采用流畅的散文段落”。
- 提示风格与输出风格匹配：若希望输出少用Markdown，自身提示中也应减少Markdown使用。
- 明确格式偏好：详细说明格式要求。示例：“撰写报告时使用完整段落和标准分段，Markdown仅用于行内代码、代码块和简单标题；非必要不使用有序/无序列表，将内容自然融入句子中”。

### 4. 提示链

定义：将复杂任务拆分为多个连续步骤，每个步骤用单独提示处理，前一步输出作为后一步输入。

核心优势：以增加延迟为代价，提高每个子任务的准确性，适合需要迭代优化或中间验证的场景。

适用场景：
- 复杂请求需拆分步骤。
- 需要迭代优化输出。
- 多阶段分析任务。
- 中间验证能提升最终质量。
- 单条提示输出结果不一致。

示例（研究总结）：
1. 第一条提示：“总结这篇医学论文，涵盖方法、发现和临床意义”。
2. 第二条提示：“审查上述总结的准确性、清晰度和完整性，提供分级反馈”。
3. 第三条提示：“根据以下反馈优化总结：[第二步的反馈内容]”。

## 三、技术整合使用提示

### 1. 尝试通过多技术组合达到目的

```
从这份季度报告中提取关键财务指标，以JSON格式呈现。该数据用于自动化处理，因此响应必须仅包含有效JSON，无开场白或解释。使用以下结构：{\"revenue\":\"带单位的值\",\"profit_margin\":\"百分比\",\"growth_rate\":\"百分比\"}。若报告中未明确说明某指标，用null表示，不要猜测。响应以左大括号开头：{
```

### 2. 技术选择决策框架

**基础判断步骤**
- 需求是否清晰明确？若否，优先优化清晰度。
- 任务是否简单？是则仅使用核心技术（明确、具体、提供上下文）。
- 是否需要特定格式？使用示例、预填充或明确格式指令。
- 任务是否复杂？考虑拆分任务（提示链）。
- 是否需要推理？使用“扩展思考”（若可用）或思维链。

**技术-需求匹配表**

  | 需求场景 | 推荐技术 |
  |---|---|
  | 特定输出格式 | 示例、预填充、明确格式指令 |
  | 分步推理 | 扩展思考（Claude 4.x）、思维链 |
  | 复杂多阶段任务 | 提示链 |
  | 透明推理过程 | 带结构化输出的思维链 |
  | 防止幻觉 | 允许AI说“不知道” |

### 3. 常见问题故障排除

  | 问题现象 | 解决方案 |
  |---|---|
  | 输出过于通用 | 增加特异性描述、提供示例、明确要求“超越基础内容” |
  | 输出偏离主题或未击中要点 | 更明确地说明核心目标，提供需求背后的上下文 |
  | 输出格式不一致 | 添加示例（少样本）或使用预填充控制响应开头 |
  | 任务复杂导致结果不可靠 | 拆分为多个提示（提示链），每个提示专注单一任务 |
  | AI添加不必要的开场白 | 使用预填充或明确要求“跳过开场白，直接给出答案” |
  | AI虚构信息（幻觉） | 明确允许AI在不确定时说明“不知道” |
  | 期望执行操作，AI却仅提供建议 | 明确动作指令（如“修改此函数”而非“你能建议修改吗？”） |

### 4. 实用技巧
- 从简单提示开始，仅在需要时添加复杂技术。
- 每次添加技术后测试效果，确认是否真的提升输出质量。

## 四、常见错误与避坑指南
1. 过度设计：更长、更复杂的提示不一定更好。
2. 忽视基础：核心提示模糊不清时，高级技术无法弥补。
3. 假设AI能“读心”：不明确的需求会导致AI误解，需具体化所有要求。
4. 滥用技术：无需同时使用所有技术，仅选择解决特定问题的方法。
5. 不迭代优化：首次提示极少完美，需测试并调整。
6. 依赖过时技术：XML标签和过度角色提示对现代模型必要性低，优先使用明确指令。

## 五、最终建议
1. 核心定位：提示工程本质是“沟通”，即用AI能清晰理解的语言表达意图。
2. 学习路径：先熟练掌握核心技术，形成习惯后，仅在解决特定问题时添加高级技术。
3. 优质提示的关键：并非最长或最复杂，而是能以最少的结构可靠达成目标。
4. 与上下文工程的关系：提示工程是上下文工程的基础，每一个优质提示都是塑造AI行为的重要组成部分。

## 参考

原文：[Best practices for prompt engineering](https://claude.com/blog/best-practices-for-prompt-engineering)